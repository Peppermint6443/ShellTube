{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.optimize as opt\n",
    "from scipy.integrate import odeint, quad\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from byutpl.properties import water as water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Constants ----- #\n",
    "# heat exchanger physical parameters\n",
    "di = .206 * 2.54 / 100                  # m\n",
    "do = .25 * 2.54 / 100                   # m\n",
    "L = 14 * 2.54 / 100                     # m\n",
    "k = 13.4                                # W/m.K 316 SS\n",
    "g = 9.81                                # m/s^2\n",
    "N = 56                                  # number of tubes    \n",
    "\n",
    "# calculate the heat transfer area\n",
    "Ai = .25 * np.pi * di**2\n",
    "Ao = .25 * np.pi * do**2\n",
    "\n",
    "# ----- Functions ----- #\n",
    "def hi(Qi,Ti):\n",
    "    # calculate the velocity\n",
    "    v = Qi / Ai\n",
    "\n",
    "    # calculate the Reynolds number\n",
    "    Re = water.ldn(Ti) * v * di / water.lvs(Ti)\n",
    "\n",
    "    # calculate the Nusselt number\n",
    "    if Re < 10000:\n",
    "        Nu = 3.66\n",
    "    else:\n",
    "        Nu = .023 * (Re**.8) * water.lpr(Ti)**.4\n",
    "\n",
    "    # calculate heat transfer coefficient\n",
    "    h = Nu * water.ltc(Ti) / di\n",
    "    return h\n",
    "\n",
    "def ho(Ps,Ts):\n",
    "    # pull in the values\n",
    "    rhol = water.ldn(Ts)\n",
    "    rhov = water.vdn(Ts,Ps)\n",
    "    kl = water.ltc(Ts)\n",
    "    mul = water.lvs(Ts)\n",
    "    Tsat = water.tsat(Ps)\n",
    "    cpl = water.lcp(Ts) / water.mw\n",
    "    hfg = water.hvp(Ts) / water.mw\n",
    "\n",
    "    # find Ja\n",
    "    Ja = cpl * (Tsat - Ts) / hfg\n",
    "\n",
    "    # calculate the condensation energy\n",
    "    hfp = hfg * (1 + (.68 * Ja))\n",
    "\n",
    "    # calculate the heat transfer coefficient\n",
    "    h = .729 * (rhol * g * (rhol - rhov) * hfp * kl**3 / (N * mul * (Tsat - Ts) * do))**.25\n",
    "    return h\n",
    "\n",
    "def model(inputs,Rf):\n",
    "    Qw,Ps,Tweff = inputs\n",
    "\n",
    "    #                       |                 |                                 |\n",
    "    #      convection_inner | fouling_inner   |             conduction          | convection_outer\n",
    "    #                       |                 |                                 |\n",
    "    UA = (hi(Qw, Tweff) * Ai)**-1 + (Rf / Ai) + (np.log(do / di) / (2 * np.pi * k * L)) + (ho(Ps, Tweff) / Ao)**-1\n",
    "    return UA\n",
    "\n",
    "model = np.vectorize(model)\n",
    "\n",
    "\n",
    "# correlation for if we want to try to fit both fouling factors\n",
    "\n",
    "# Qi,Qo = Qs\n",
    "# #                       |                 |                                  |                 |\n",
    "# #      convection_inner | fouling_inner   |             conduction           |  fouling_outer  | convection_outer\n",
    "# #                       |                 |                                  |                 |\n",
    "# sumR = (hi(Qi) * Ai)**-1 + (Rfi / Ai) + (np.log(do / di) / (2 * np.pi * k * L)) + (Rfo / Ao) + (ho(Qo) / Ao)**-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$UA = (\\Sigma R)^-1 = \\frac{1}{h_i(\\dot V)A_i} + \\frac{R_{f,i}^\"}{A_i} + \\frac{ln(d_o / d_i)}{2\\pi kL}+ \\frac{R_{f,o}^\"}{A_o} + \\frac{1}{h_o(\\dot V)A_o}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time (sec)', 'Water Level (ft)', 'Water Flowrate (GPM)',\n",
      "       'House Steam Pressure (psig)', 'Steam Pressure (psig)',\n",
      "       'Inlet Water Temperature (C)', 'Outlet Water Temperature (C)',\n",
      "       'Makeup Temperature (C)', 'Makeup Flowrate (L/min)',\n",
      "       'Ambient Temperature (C)', 'Ambient Pressure (kPa)',\n",
      "       'Flow Setpoint (GPM)', 'Flow Control Output (%)', 'Level Setpoint (ft)',\n",
      "       'Level Control Output (%)', 'Steam Setpoint (psig)',\n",
      "       'Steam Control Output (%)', 'Tube-Side Pressure Drop (psig)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('data/Trial1.csv')\n",
    "data2 = pd.read_csv('data/Trial2.csv')\n",
    "data3 = pd.read_csv('data/Trial3.csv')\n",
    "\n",
    "data_collection = np.array([data1,data2,data3])\n",
    "\n",
    "print(data1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = np.array([])\n",
    "Twout = np.array([])\n",
    "Twin = np.array([])\n",
    "Ps = np.array([])\n",
    "\n",
    "for i, df in enumerate(data_collection):\n",
    "    qs = np.append(qs,df[:,2])\n",
    "    Twout = np.append(Twout,df[:,6])\n",
    "    Twin = np.append(Twin,df[:,5])\n",
    "    Ps = np.append(Ps,df[:,4])\n",
    "\n",
    "    \n",
    "Tavg = (Twout + Twin) / 2\n",
    "\n",
    "# conver the data to SI units\n",
    "qs_good = qs * 6.30901964e-5                # gal/min to m^3/s\n",
    "Ps_good = (Ps + 14.7) * 101325 / 14.7       # psig to Pa\n",
    "Cpw = water.lcp(Tavg + 273.15) / water.mw   # J/kg.K\n",
    "\n",
    "tsat = np.vectorize(water.tsat)\n",
    "\n",
    "Tsat = tsat(Ps_good)\n",
    "\n",
    "# calculate the delta T values\n",
    "dT1 = Tsat - Twout\n",
    "dT2 = Tsat - Twin\n",
    "\n",
    "# calcualate the delta T log mean\n",
    "dTlm = (dT1 - dT2) / np.log(dT1 / dT2)\n",
    "\n",
    "# calculate the mass flow rate of the water \n",
    "rho = water.ldn(Tavg + 273.15)\n",
    "m = qs_good / rho\n",
    "\n",
    "# find the heat transfer\n",
    "Q = -m * Cpw * (Twin - Twout)\n",
    "\n",
    "# calculate the heat transfer coefficient\n",
    "UA = Q / dTlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to determine number of fit parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit the data with the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Rf \u001b[38;5;241m=\u001b[39m \u001b[43mcurve_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mqs_good\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPs_good\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTavg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m273.15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(Rf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\optimize\\_minpack_py.py:901\u001b[0m, in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001b[0m\n\u001b[0;32m    899\u001b[0m     args \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to determine number of fit parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    902\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to determine number of fit parameters."
     ]
    }
   ],
   "source": [
    "# fit the data with the model\n",
    "Rf = curve_fit(model, [qs_good,Ps_good,Tavg + 273.15], UA)\n",
    "\n",
    "print(Rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function curve_fit in module scipy.optimize._minpack_py:\n",
      "\n",
      "curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False, check_finite=None, bounds=(-inf, inf), method=None, jac=None, *, full_output=False, nan_policy=None, **kwargs)\n",
      "    Use non-linear least squares to fit a function, f, to data.\n",
      "\n",
      "    Assumes ``ydata = f(xdata, *params) + eps``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    f : callable\n",
      "        The model function, f(x, ...). It must take the independent\n",
      "        variable as the first argument and the parameters to fit as\n",
      "        separate remaining arguments.\n",
      "    xdata : array_like\n",
      "        The independent variable where the data is measured.\n",
      "        Should usually be an M-length sequence or an (k,M)-shaped array for\n",
      "        functions with k predictors, and each element should be float\n",
      "        convertible if it is an array like object.\n",
      "    ydata : array_like\n",
      "        The dependent data, a length M array - nominally ``f(xdata, ...)``.\n",
      "    p0 : array_like, optional\n",
      "        Initial guess for the parameters (length N). If None, then the\n",
      "        initial values will all be 1 (if the number of parameters for the\n",
      "        function can be determined using introspection, otherwise a\n",
      "        ValueError is raised).\n",
      "    sigma : None or scalar or M-length sequence or MxM array, optional\n",
      "        Determines the uncertainty in `ydata`. If we define residuals as\n",
      "        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma`\n",
      "        depends on its number of dimensions:\n",
      "\n",
      "        - A scalar or 1-D `sigma` should contain values of standard deviations of\n",
      "          errors in `ydata`. In this case, the optimized function is\n",
      "          ``chisq = sum((r / sigma) ** 2)``.\n",
      "\n",
      "        - A 2-D `sigma` should contain the covariance matrix of\n",
      "          errors in `ydata`. In this case, the optimized function is\n",
      "          ``chisq = r.T @ inv(sigma) @ r``.\n",
      "\n",
      "          .. versionadded:: 0.19\n",
      "\n",
      "        None (default) is equivalent of 1-D `sigma` filled with ones.\n",
      "    absolute_sigma : bool, optional\n",
      "        If True, `sigma` is used in an absolute sense and the estimated parameter\n",
      "        covariance `pcov` reflects these absolute values.\n",
      "\n",
      "        If False (default), only the relative magnitudes of the `sigma` values matter.\n",
      "        The returned parameter covariance matrix `pcov` is based on scaling\n",
      "        `sigma` by a constant factor. This constant is set by demanding that the\n",
      "        reduced `chisq` for the optimal parameters `popt` when using the\n",
      "        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to\n",
      "        match the sample variance of the residuals after the fit. Default is False.\n",
      "        Mathematically,\n",
      "        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)``\n",
      "    check_finite : bool, optional\n",
      "        If True, check that the input arrays do not contain nans of infs,\n",
      "        and raise a ValueError if they do. Setting this parameter to\n",
      "        False may silently produce nonsensical results if the input arrays\n",
      "        do contain nans. Default is True if `nan_policy` is not specified\n",
      "        explicitly and False otherwise.\n",
      "    bounds : 2-tuple of array_like or `Bounds`, optional\n",
      "        Lower and upper bounds on parameters. Defaults to no bounds.\n",
      "        There are two ways to specify the bounds:\n",
      "\n",
      "        - Instance of `Bounds` class.\n",
      "\n",
      "        - 2-tuple of array_like: Each element of the tuple must be either\n",
      "          an array with the length equal to the number of parameters, or a\n",
      "          scalar (in which case the bound is taken to be the same for all\n",
      "          parameters). Use ``np.inf`` with an appropriate sign to disable\n",
      "          bounds on all or some parameters.\n",
      "\n",
      "    method : {'lm', 'trf', 'dogbox'}, optional\n",
      "        Method to use for optimization. See `least_squares` for more details.\n",
      "        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are\n",
      "        provided. The method 'lm' won't work when the number of observations\n",
      "        is less than the number of variables, use 'trf' or 'dogbox' in this\n",
      "        case.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "    jac : callable, string or None, optional\n",
      "        Function with signature ``jac(x, ...)`` which computes the Jacobian\n",
      "        matrix of the model function with respect to parameters as a dense\n",
      "        array_like structure. It will be scaled according to provided `sigma`.\n",
      "        If None (default), the Jacobian will be estimated numerically.\n",
      "        String keywords for 'trf' and 'dogbox' methods can be used to select\n",
      "        a finite difference scheme, see `least_squares`.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "    full_output : boolean, optional\n",
      "        If True, this function returns additional information: `infodict`,\n",
      "        `mesg`, and `ier`.\n",
      "\n",
      "        .. versionadded:: 1.9\n",
      "    nan_policy : {'raise', 'omit', None}, optional\n",
      "        Defines how to handle when input contains nan.\n",
      "        The following options are available (default is None):\n",
      "\n",
      "        * 'raise': throws an error\n",
      "        * 'omit': performs the calculations ignoring nan values\n",
      "        * None: no special handling of NaNs is performed\n",
      "          (except what is done by check_finite); the behavior when NaNs\n",
      "          are present is implementation-dependent and may change.\n",
      "\n",
      "        Note that if this value is specified explicitly (not None),\n",
      "        `check_finite` will be set as False.\n",
      "\n",
      "        .. versionadded:: 1.11\n",
      "    **kwargs\n",
      "        Keyword arguments passed to `leastsq` for ``method='lm'`` or\n",
      "        `least_squares` otherwise.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    popt : array\n",
      "        Optimal values for the parameters so that the sum of the squared\n",
      "        residuals of ``f(xdata, *popt) - ydata`` is minimized.\n",
      "    pcov : 2-D array\n",
      "        The estimated approximate covariance of popt. The diagonals provide\n",
      "        the variance of the parameter estimate. To compute one standard\n",
      "        deviation errors on the parameters, use\n",
      "        ``perr = np.sqrt(np.diag(pcov))``. Note that the relationship between\n",
      "        `cov` and parameter error estimates is derived based on a linear\n",
      "        approximation to the model function around the optimum [1]_.\n",
      "        When this approximation becomes inaccurate, `cov` may not provide an\n",
      "        accurate measure of uncertainty.\n",
      "\n",
      "        How the `sigma` parameter affects the estimated covariance\n",
      "        depends on `absolute_sigma` argument, as described above.\n",
      "\n",
      "        If the Jacobian matrix at the solution doesn't have a full rank, then\n",
      "        'lm' method returns a matrix filled with ``np.inf``, on the other hand\n",
      "        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute\n",
      "        the covariance matrix. Covariance matrices with large condition numbers\n",
      "        (e.g. computed with `numpy.linalg.cond`) may indicate that results are\n",
      "        unreliable.\n",
      "    infodict : dict (returned only if `full_output` is True)\n",
      "        a dictionary of optional outputs with the keys:\n",
      "\n",
      "        ``nfev``\n",
      "            The number of function calls. Methods 'trf' and 'dogbox' do not\n",
      "            count function calls for numerical Jacobian approximation,\n",
      "            as opposed to 'lm' method.\n",
      "        ``fvec``\n",
      "            The residual values evaluated at the solution, for a 1-D `sigma`\n",
      "            this is ``(f(x, *popt) - ydata)/sigma``.\n",
      "        ``fjac``\n",
      "            A permutation of the R matrix of a QR\n",
      "            factorization of the final approximate\n",
      "            Jacobian matrix, stored column wise.\n",
      "            Together with ipvt, the covariance of the\n",
      "            estimate can be approximated.\n",
      "            Method 'lm' only provides this information.\n",
      "        ``ipvt``\n",
      "            An integer array of length N which defines\n",
      "            a permutation matrix, p, such that\n",
      "            fjac*p = q*r, where r is upper triangular\n",
      "            with diagonal elements of nonincreasing\n",
      "            magnitude. Column j of p is column ipvt(j)\n",
      "            of the identity matrix.\n",
      "            Method 'lm' only provides this information.\n",
      "        ``qtf``\n",
      "            The vector (transpose(q) * fvec).\n",
      "            Method 'lm' only provides this information.\n",
      "\n",
      "        .. versionadded:: 1.9\n",
      "    mesg : str (returned only if `full_output` is True)\n",
      "        A string message giving information about the solution.\n",
      "\n",
      "        .. versionadded:: 1.9\n",
      "    ier : int (returned only if `full_output` is True)\n",
      "        An integer flag. If it is equal to 1, 2, 3 or 4, the solution was\n",
      "        found. Otherwise, the solution was not found. In either case, the\n",
      "        optional output variable `mesg` gives more information.\n",
      "\n",
      "        .. versionadded:: 1.9\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        if either `ydata` or `xdata` contain NaNs, or if incompatible options\n",
      "        are used.\n",
      "\n",
      "    RuntimeError\n",
      "        if the least-squares minimization fails.\n",
      "\n",
      "    OptimizeWarning\n",
      "        if covariance of the parameters can not be estimated.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    least_squares : Minimize the sum of squares of nonlinear functions.\n",
      "    scipy.stats.linregress : Calculate a linear least squares regression for\n",
      "                             two sets of measurements.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Users should ensure that inputs `xdata`, `ydata`, and the output of `f`\n",
      "    are ``float64``, or else the optimization may return incorrect results.\n",
      "\n",
      "    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm\n",
      "    through `leastsq`. Note that this algorithm can only deal with\n",
      "    unconstrained problems.\n",
      "\n",
      "    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to\n",
      "    the docstring of `least_squares` for more information.\n",
      "\n",
      "    Parameters to be fitted must have similar scale. Differences of multiple\n",
      "    orders of magnitude can lead to incorrect results. For the 'trf' and\n",
      "    'dogbox' methods, the `x_scale` keyword argument can be used to scale\n",
      "    the parameters.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] K. Vugrin et al. Confidence region estimation techniques for nonlinear\n",
      "           regression in groundwater flow: Three case studies. Water Resources\n",
      "           Research, Vol. 43, W03423, :doi:`10.1029/2005WR004804`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy.optimize import curve_fit\n",
      "\n",
      "    >>> def func(x, a, b, c):\n",
      "    ...     return a * np.exp(-b * x) + c\n",
      "\n",
      "    Define the data to be fit with some noise:\n",
      "\n",
      "    >>> xdata = np.linspace(0, 4, 50)\n",
      "    >>> y = func(xdata, 2.5, 1.3, 0.5)\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> y_noise = 0.2 * rng.normal(size=xdata.size)\n",
      "    >>> ydata = y + y_noise\n",
      "    >>> plt.plot(xdata, ydata, 'b-', label='data')\n",
      "\n",
      "    Fit for the parameters a, b, c of the function `func`:\n",
      "\n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata)\n",
      "    >>> popt\n",
      "    array([2.56274217, 1.37268521, 0.47427475])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'r-',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "\n",
      "    Constrain the optimization to the region of ``0 <= a <= 3``,\n",
      "    ``0 <= b <= 1`` and ``0 <= c <= 0.5``:\n",
      "\n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
      "    >>> popt\n",
      "    array([2.43736712, 1.        , 0.34463856])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'g--',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "\n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.ylabel('y')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n",
      "    For reliable results, the model `func` should not be overparametrized;\n",
      "    redundant parameters can cause unreliable covariance matrices and, in some\n",
      "    cases, poorer quality fits. As a quick check of whether the model may be\n",
      "    overparameterized, calculate the condition number of the covariance matrix:\n",
      "\n",
      "    >>> np.linalg.cond(pcov)\n",
      "    34.571092161547405  # may vary\n",
      "\n",
      "    The value is small, so it does not raise much concern. If, however, we were\n",
      "    to add a fourth parameter ``d`` to `func` with the same effect as ``a``:\n",
      "\n",
      "    >>> def func2(x, a, b, c, d):\n",
      "    ...     return a * d * np.exp(-b * x) + c  # a and d are redundant\n",
      "    >>> popt, pcov = curve_fit(func2, xdata, ydata)\n",
      "    >>> np.linalg.cond(pcov)\n",
      "    1.13250718925596e+32  # may vary\n",
      "\n",
      "    Such a large value is cause for concern. The diagonal elements of the\n",
      "    covariance matrix, which is related to uncertainty of the fit, gives more\n",
      "    information:\n",
      "\n",
      "    >>> np.diag(pcov)\n",
      "    array([1.48814742e+29, 3.78596560e-02, 5.39253738e-03, 2.76417220e+28])  # may vary\n",
      "\n",
      "    Note that the first and last terms are much larger than the other elements,\n",
      "    suggesting that the optimal values of these parameters are ambiguous and\n",
      "    that only one of these parameters is needed in the model.\n",
      "\n",
      "    If the optimal parameters of `f` differ by multiple orders of magnitude, the\n",
      "    resulting fit can be inaccurate. Sometimes, `curve_fit` can fail to find any\n",
      "    results:\n",
      "\n",
      "    >>> ydata = func(xdata, 500000, 0.01, 15)\n",
      "    >>> try:\n",
      "    ...     popt, pcov = curve_fit(func, xdata, ydata, method = 'trf')\n",
      "    ... except RuntimeError as e:\n",
      "    ...     print(e)\n",
      "    Optimal parameters not found: The maximum number of function evaluations is\n",
      "    exceeded.\n",
      "\n",
      "    If parameter scale is roughly known beforehand, it can be defined in\n",
      "    `x_scale` argument:\n",
      "\n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, method = 'trf',\n",
      "    ...                        x_scale = [1000, 1, 1])\n",
      "    >>> popt\n",
      "    array([5.00000000e+05, 1.00000000e-02, 1.49999999e+01])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(curve_fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
